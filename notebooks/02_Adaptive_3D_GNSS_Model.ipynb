{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7250cbc",
   "metadata": {},
   "source": [
    "# üöÄ Adaptive 3D GNSS Degradation Model\n",
    "## Multi-Dimensional Spatial Analysis with Auto-Feature Selection\n",
    "\n",
    "**Author:** Sofia Buriak  \n",
    "**Version:** 2.1 (Advanced Diploma)  \n",
    "**Date:** January 2026\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Mission Statement\n",
    "\n",
    "This notebook implements a **3D Spatial Regression Model** that predicts degradation across three dimensions:\n",
    "\n",
    "| Dimension | Target | Critical For |\n",
    "|-----------|--------|-------------|\n",
    "| **1D** | `vAcc` (Vertical) | Terrain collision avoidance |\n",
    "| **2D** | `hAcc` (Horizontal) | Route navigation |\n",
    "| **3D** | $\\sqrt{hAcc^2 + vAcc^2}$ | Overall positioning |\n",
    "\n",
    "### üí° Key Innovations\n",
    "\n",
    "1. **Auto-Correlation Analysis:** Automatically identifies optimal features for each dimension\n",
    "2. **Physics-Based Engineering:** Signal energy, geometric stress, satellite efficiency\n",
    "3. **Max-Based Target:** $Score = \\max(Norm(hAcc), Norm(vAcc), Norm(3D))$\n",
    "4. **Adaptive XGBoost:** Recall-optimized hyperparameters\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784d95f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: IMPORTS & CONFIGURATION\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, \n",
    "    mean_squared_error,\n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    classification_report\n",
    ")\n",
    "import warnings\n",
    "import gc\n",
    "import os\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# ========== CONFIGURATION ==========\n",
    "CONFIG = {\n",
    "    'DATA_PATH': '../data/processed/all_data_compressed.parquet',\n",
    "    'MODEL_OUTPUT_PATH': '../models/gnss_adaptive_3d.json',\n",
    "    'CONFIG_OUTPUT_PATH': '../models/gnss_adaptive_3d_config.json',\n",
    "    \n",
    "    # Target Engineering\n",
    "    'SAFE_LIMIT_MM': 5000,      # 5 meters ‚Äî Safe zone\n",
    "    'FAIL_LIMIT_MM': 50000,     # 50 meters ‚Äî Critical zone\n",
    "    \n",
    "    # Train/Test Split\n",
    "    'TEST_START_DATE': '2025-12-01',\n",
    "    \n",
    "    # Model Hyperparameters (Diploma Verified)\n",
    "    'XGB_PARAMS': {\n",
    "        'n_estimators': 300,\n",
    "        'max_depth': 7,\n",
    "        'learning_rate': 0.03,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'objective': 'reg:logistic',\n",
    "        'tree_method': 'hist',\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42\n",
    "    },\n",
    "    \n",
    "    # Auto-Feature Selection\n",
    "    'MIN_CORRELATION': 0.05\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"   Safe Limit: {CONFIG['SAFE_LIMIT_MM']/1000:.1f}m\")\n",
    "print(f\"   Fail Limit: {CONFIG['FAIL_LIMIT_MM']/1000:.1f}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa7a75b",
   "metadata": {},
   "source": [
    "---\n",
    "## üìÇ Step 1: Data Loading\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: DATA LOADING\n",
    "# ============================================================\n",
    "print(\"üìÇ LOADING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    df = pd.read_parquet(CONFIG['DATA_PATH'])\n",
    "    print(f\"   ‚úÖ Loaded from parquet: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"   ‚ö†Ô∏è Parquet not found. Loading from raw CSV...\")\n",
    "    import sys\n",
    "    sys.path.append('..')\n",
    "    from src.data_loader import load_all_data\n",
    "    df = load_all_data('../data/raw')\n",
    "\n",
    "# Sort by time\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "# Ensure datetime\n",
    "if not np.issubdtype(df['timestamp'].dtype, np.datetime64):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Memory optimization\n",
    "float_cols = df.select_dtypes(include=['float64']).columns\n",
    "df[float_cols] = df[float_cols].astype(np.float32)\n",
    "\n",
    "print(f\"\\nüìä Dataset Summary:\")\n",
    "print(f\"   Samples: {len(df):,}\")\n",
    "print(f\"   Time range: {df['timestamp'].min()} ‚Üí {df['timestamp'].max()}\")\n",
    "print(f\"   Memory: {df.memory_usage(deep=True).sum() / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c084758",
   "metadata": {},
   "source": [
    "---\n",
    "## üî¨ Step 2: Preliminary Data Intelligence\n",
    "\n",
    "### Automatic Correlation Analysis:\n",
    "1. Which factors most affect **1D error** (vAcc)? Hypothesis: `vDOP`, `cnoStd`\n",
    "2. Which factors affect **2D error** (hAcc)? Hypothesis: `hDOP`, `numSV`\n",
    "3. Auto-generate feature list, rejecting weak correlations (< 0.05)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abbd414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: AUTOMATIC CORRELATION ANALYSIS\n",
    "# ============================================================\n",
    "print(\"üî¨ PRELIMINARY DATA INTELLIGENCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate 3D error\n",
    "df['error_3d'] = np.sqrt(df['hAcc']**2 + df['vAcc']**2).astype(np.float32)\n",
    "\n",
    "# Identify potential features\n",
    "EXCLUDE_COLS = [\n",
    "    'timestamp', 'hAcc', 'vAcc', 'sAcc', 'tAcc', 'error_3d',\n",
    "    'overallPositionLabel', 'horizontalPositionLabel', 'verticalPositionLabel'\n",
    "]\n",
    "\n",
    "feature_cols = [col for col in df.columns \n",
    "                if col not in EXCLUDE_COLS \n",
    "                and df[col].dtype in ['float32', 'float64', 'int64', 'int32', 'int8', 'int16']]\n",
    "\n",
    "print(f\"\\nüìã Candidate features: {len(feature_cols)}\")\n",
    "\n",
    "# Compute correlations\n",
    "correlations = {\n",
    "    '1D (vAcc)': {},\n",
    "    '2D (hAcc)': {},\n",
    "    '3D (Spatial)': {}\n",
    "}\n",
    "\n",
    "for feat in feature_cols:\n",
    "    if df[feat].notna().sum() > 1000:\n",
    "        correlations['1D (vAcc)'][feat] = df[feat].corr(df['vAcc'])\n",
    "        correlations['2D (hAcc)'][feat] = df[feat].corr(df['hAcc'])\n",
    "        correlations['3D (Spatial)'][feat] = df[feat].corr(df['error_3d'])\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).dropna()\n",
    "corr_df = corr_df.reindex(corr_df['3D (Spatial)'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(\"\\nüìà CORRELATION TABLE (sorted by 3D impact):\")\n",
    "print(\"-\"*50)\n",
    "display(corr_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e43df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: HYPOTHESIS VALIDATION\n",
    "# ============================================================\n",
    "print(\"\\nüß™ HYPOTHESIS VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Hypothesis 1: vDOP and cnoStd affect vAcc\n",
    "print(\"\\nüìê Hypothesis 1: vDOP and cnoStd ‚Üí vAcc (1D)\")\n",
    "if 'vDOP' in corr_df.index:\n",
    "    vdop_corr = corr_df.loc['vDOP', '1D (vAcc)']\n",
    "    print(f\"   vDOP ‚Üí vAcc:  r = {vdop_corr:.4f} {'‚úÖ CONFIRMED' if abs(vdop_corr) > 0.1 else '‚ö†Ô∏è WEAK'}\")\n",
    "if 'cnoStd' in corr_df.index:\n",
    "    cnostd_corr = corr_df.loc['cnoStd', '1D (vAcc)']\n",
    "    print(f\"   cnoStd ‚Üí vAcc: r = {cnostd_corr:.4f} {'‚úÖ CONFIRMED' if abs(cnostd_corr) > 0.1 else '‚ö†Ô∏è WEAK'}\")\n",
    "\n",
    "# Hypothesis 2: hDOP and numSV affect hAcc\n",
    "print(\"\\nüìê Hypothesis 2: hDOP and numSV ‚Üí hAcc (2D)\")\n",
    "if 'hDOP' in corr_df.index:\n",
    "    hdop_corr = corr_df.loc['hDOP', '2D (hAcc)']\n",
    "    print(f\"   hDOP ‚Üí hAcc:  r = {hdop_corr:.4f} {'‚úÖ CONFIRMED' if abs(hdop_corr) > 0.1 else '‚ö†Ô∏è WEAK'}\")\n",
    "if 'numSV' in corr_df.index:\n",
    "    numsv_corr = corr_df.loc['numSV', '2D (hAcc)']\n",
    "    print(f\"   numSV ‚Üí hAcc: r = {numsv_corr:.4f} {'‚úÖ CONFIRMED' if abs(numsv_corr) > 0.05 else '‚ö†Ô∏è WEAK'}\")\n",
    "\n",
    "# Auto-select features\n",
    "threshold = CONFIG['MIN_CORRELATION']\n",
    "AUTO_SELECTED = corr_df[\n",
    "    (corr_df['3D (Spatial)'].abs() >= threshold) | \n",
    "    (corr_df['1D (vAcc)'].abs() >= threshold) |\n",
    "    (corr_df['2D (hAcc)'].abs() >= threshold)\n",
    "].index.tolist()\n",
    "\n",
    "print(f\"\\n‚úÖ AUTO-SELECTED FEATURES ({len(AUTO_SELECTED)}):\")\n",
    "for i, feat in enumerate(AUTO_SELECTED, 1):\n",
    "    print(f\"   {i:2d}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fa32c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: CORRELATION HEATMAP\n",
    "# ============================================================\n",
    "fig, ax = plt.subplots(figsize=(10, max(6, len(corr_df)*0.4)))\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(corr_df, annot=True, fmt='.3f', cmap='RdBu_r', \n",
    "            center=0, vmin=-1, vmax=1, ax=ax,\n",
    "            linewidths=0.5, linecolor='white')\n",
    "\n",
    "ax.set_title('üî¨ Feature-Error Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Error Dimension')\n",
    "ax.set_ylabel('Feature')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/correlation_heatmap_3d.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b7885",
   "metadata": {},
   "source": [
    "---\n",
    "## üõ†Ô∏è Step 3: Advanced Feature Engineering\n",
    "\n",
    "### Physics-Based Features:\n",
    "\n",
    "| Feature | Formula | Physical Meaning |\n",
    "|---------|---------|------------------|\n",
    "| Signal Energy | `cnoMean √ó numSV` | Total constellation power |\n",
    "| Sat Efficiency | `numSatsTracked / numSV` | Tracking quality |\n",
    "| Geometric Stress | `vDOP √ó hDOP` | Combined poor geometry |\n",
    "| CNO Derivative | `diff(cnoMean)` | Signal change rate |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df14bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: ADVANCED FEATURE ENGINEERING\n",
    "# ============================================================\n",
    "print(\"üõ†Ô∏è ADVANCED FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Set timestamp as index for rolling operations\n",
    "df = df.set_index('timestamp')\n",
    "\n",
    "# ========== PHYSICS-BASED FEATURES ==========\n",
    "print(\"\\nüìê Creating physics-based features...\")\n",
    "\n",
    "# 1. Signal Energy\n",
    "df['signal_energy'] = (df['cnoMean'] * df['numSV']).astype(np.float32)\n",
    "print(\"   ‚úÖ signal_energy = cnoMean √ó numSV\")\n",
    "\n",
    "# 2. Satellite Efficiency\n",
    "df['sat_efficiency'] = (df['numSV'] / df['numSatsTracked'].replace(0, 1)).clip(0, 5).astype(np.float32)\n",
    "print(\"   ‚úÖ sat_efficiency = numSV / numSatsTracked\")\n",
    "\n",
    "# 3. Geometric Stress\n",
    "if 'vDOP' in df.columns and 'hDOP' in df.columns:\n",
    "    df['geometric_stress'] = (df['vDOP'] * df['hDOP']).astype(np.float32)\n",
    "    print(\"   ‚úÖ geometric_stress = vDOP √ó hDOP\")\n",
    "\n",
    "# 4. DOP Asymmetry\n",
    "if 'vDOP' in df.columns and 'hDOP' in df.columns:\n",
    "    df['dop_asymmetry'] = ((df['vDOP'] - df['hDOP']).abs()).astype(np.float32)\n",
    "    print(\"   ‚úÖ dop_asymmetry = |vDOP - hDOP|\")\n",
    "\n",
    "# ========== TEMPORAL DERIVATIVES ==========\n",
    "print(\"\\n‚è±Ô∏è Creating temporal features...\")\n",
    "\n",
    "# CNO rate of change\n",
    "df['cnoMean_diff'] = df['cnoMean'].diff().fillna(0).astype(np.float32)\n",
    "print(\"   ‚úÖ cnoMean_diff\")\n",
    "\n",
    "# Lag features\n",
    "for col in ['cnoMean', 'sat_efficiency', 'numSV']:\n",
    "    if col in df.columns:\n",
    "        df[f'{col}_lag1'] = df[col].shift(1).bfill().astype(np.float32)\n",
    "        df[f'{col}_lag5'] = df[col].shift(5).bfill().astype(np.float32)\n",
    "print(\"   ‚úÖ Lag features (t-1, t-5)\")\n",
    "\n",
    "# ========== ROLLING FEATURES (STABILITY) ==========\n",
    "print(\"\\nüìä Creating stability features...\")\n",
    "\n",
    "rolling_window = '10s'\n",
    "\n",
    "# CNO stability\n",
    "df['cnoMean_rolling_mean'] = df['cnoMean'].rolling(rolling_window).mean().astype(np.float32)\n",
    "df['cnoMean_rolling_std'] = df['cnoMean'].rolling(rolling_window).std().fillna(0).astype(np.float32)\n",
    "print(f\"   ‚úÖ cnoMean_rolling_std ({rolling_window})\")\n",
    "\n",
    "# vDOP stability\n",
    "if 'vDOP' in df.columns:\n",
    "    df['vDOP_rolling_std'] = df['vDOP'].rolling(rolling_window).std().fillna(0).astype(np.float32)\n",
    "    print(f\"   ‚úÖ vDOP_rolling_std ({rolling_window})\")\n",
    "\n",
    "# numSV stability\n",
    "df['numSV_rolling_std'] = df['numSV'].rolling(rolling_window).std().fillna(0).astype(np.float32)\n",
    "print(f\"   ‚úÖ numSV_rolling_std ({rolling_window})\")\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index()\n",
    "\n",
    "print(\"\\n‚úÖ Feature engineering complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ea5050",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Step 4: 3D Target Engineering\n",
    "\n",
    "### Max-Based Degradation Score:\n",
    "\n",
    "$$Score = \\max\\left( \\frac{hAcc - Safe}{Fail - Safe}, \\frac{vAcc - Safe}{Fail - Safe}, \\frac{\\sqrt{hAcc^2 + vAcc^2} - Safe}{Fail - Safe} \\right)$$\n",
    "\n",
    "**Rationale:** If the drone loses altitude (1D) but 2D is normal ‚Äî Score still remains high (Alert).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce2c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: 3D TARGET ENGINEERING\n",
    "# ============================================================\n",
    "print(\"üéØ 3D TARGET ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "SAFE = CONFIG['SAFE_LIMIT_MM']\n",
    "FAIL = CONFIG['FAIL_LIMIT_MM']\n",
    "\n",
    "# Individual dimension scores\n",
    "df['score_1d'] = ((df['vAcc'] - SAFE) / (FAIL - SAFE)).clip(0, 1).astype(np.float32)  # Altitude\n",
    "df['score_2d'] = ((df['hAcc'] - SAFE) / (FAIL - SAFE)).clip(0, 1).astype(np.float32)  # Horizontal\n",
    "df['score_3d'] = ((df['error_3d'] - SAFE) / (FAIL - SAFE)).clip(0, 1).astype(np.float32)  # Spatial\n",
    "\n",
    "# MAX-BASED TARGET (Most conservative)\n",
    "df['degradation_score'] = df[['score_1d', 'score_2d', 'score_3d']].max(axis=1).astype(np.float32)\n",
    "\n",
    "print(f\"\\nüìä Target Formula: Score = max(1D, 2D, 3D)\")\n",
    "print(f\"   Safe threshold: {SAFE/1000:.1f} m\")\n",
    "print(f\"   Fail threshold: {FAIL/1000:.1f} m\")\n",
    "\n",
    "print(f\"\\nüìà Score Distribution:\")\n",
    "print(f\"   Safe (< 0.1):     {(df['degradation_score'] < 0.1).sum():,} ({(df['degradation_score'] < 0.1).mean()*100:.1f}%)\")\n",
    "print(f\"   Gray (0.1-0.9):   {((df['degradation_score'] >= 0.1) & (df['degradation_score'] <= 0.9)).sum():,}\")\n",
    "print(f\"   Critical (> 0.9): {(df['degradation_score'] > 0.9).sum():,} ({(df['degradation_score'] > 0.9).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113788c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 8: DIMENSIONAL SCORE COMPARISON\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Sample for visualization\n",
    "sample = df.sample(min(50000, len(df)), random_state=42)\n",
    "\n",
    "# 1D vs 2D\n",
    "axes[0].hexbin(sample['score_1d'], sample['score_2d'], \n",
    "               gridsize=50, cmap='YlOrRd', mincnt=1)\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "axes[0].set_xlabel('1D Score (Altitude)')\n",
    "axes[0].set_ylabel('2D Score (Horizontal)')\n",
    "axes[0].set_title('1D vs 2D Score')\n",
    "\n",
    "# 2D vs 3D\n",
    "axes[1].hexbin(sample['score_2d'], sample['score_3d'], \n",
    "               gridsize=50, cmap='YlGnBu', mincnt=1)\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "axes[1].set_xlabel('2D Score (Horizontal)')\n",
    "axes[1].set_ylabel('3D Score (Spatial)')\n",
    "axes[1].set_title('2D vs 3D Score')\n",
    "\n",
    "# Final Score Distribution\n",
    "axes[2].hist(sample['degradation_score'], bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[2].axvline(0.5, color='red', linestyle='--', label='Threshold')\n",
    "axes[2].set_xlabel('Final Score (Max)')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].set_title('Final Max Score Distribution')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.suptitle('üéØ Multi-Dimensional Score Analysis', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/dimensional_scores.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4514e310",
   "metadata": {},
   "source": [
    "---\n",
    "## üìã Step 5: Feature Selection\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac25e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 9: FEATURE SELECTION\n",
    "# ============================================================\n",
    "print(\"üìã FINAL FEATURE SELECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Forbidden (target-related)\n",
    "FORBIDDEN = [\n",
    "    'timestamp', 'hAcc', 'vAcc', 'sAcc', 'tAcc', 'error_3d',\n",
    "    'score_1d', 'score_2d', 'score_3d', 'degradation_score',\n",
    "    'overallPositionLabel', 'horizontalPositionLabel', 'verticalPositionLabel'\n",
    "]\n",
    "\n",
    "# Build feature list\n",
    "FEATURE_GROUPS = {\n",
    "    'Core Signal': ['cnoMean', 'cnoStd', 'cnoMin', 'cnoMax'],\n",
    "    'Satellites': ['numSV', 'numSatsTracked'],\n",
    "    'Geometry (DOP)': ['vDOP', 'hDOP', 'pDOP', 'gDOP', 'nDOP', 'eDOP', 'tDOP'],\n",
    "    'Engineered': ['signal_energy', 'sat_efficiency', 'geometric_stress', 'dop_asymmetry', 'cnoMean_diff'],\n",
    "    'Stability': ['cnoMean_rolling_std', 'cnoMean_rolling_mean', 'vDOP_rolling_std', 'numSV_rolling_std'],\n",
    "    'Temporal': [c for c in df.columns if 'lag' in c]\n",
    "}\n",
    "\n",
    "FINAL_FEATURES = []\n",
    "for group, features in FEATURE_GROUPS.items():\n",
    "    valid = [f for f in features if f in df.columns and f not in FORBIDDEN]\n",
    "    FINAL_FEATURES.extend(valid)\n",
    "    print(f\"   {group}: {len(valid)} features\")\n",
    "\n",
    "# Remove duplicates\n",
    "FINAL_FEATURES = list(dict.fromkeys(FINAL_FEATURES))\n",
    "\n",
    "print(f\"\\n‚úÖ TOTAL FEATURES: {len(FINAL_FEATURES)}\")\n",
    "\n",
    "# Fill NaN\n",
    "for col in FINAL_FEATURES:\n",
    "    df[col] = df[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd47f529",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚úÇÔ∏è Step 6: Train/Test Split\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ee4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 10: TRAIN/TEST SPLIT\n",
    "# ============================================================\n",
    "print(\"‚úÇÔ∏è TEMPORAL TRAIN/TEST SPLIT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "split_date = pd.Timestamp(CONFIG['TEST_START_DATE'])\n",
    "\n",
    "train_mask = df['timestamp'] < split_date\n",
    "test_mask = df['timestamp'] >= split_date\n",
    "\n",
    "X_train = df.loc[train_mask, FINAL_FEATURES].copy()\n",
    "y_train = df.loc[train_mask, 'degradation_score'].copy()\n",
    "\n",
    "X_test = df.loc[test_mask, FINAL_FEATURES].copy()\n",
    "y_test = df.loc[test_mask, 'degradation_score'].copy()\n",
    "\n",
    "# Store for later analysis\n",
    "test_df = df[test_mask].copy()\n",
    "\n",
    "print(f\"   Train: {len(X_train):,} (before {split_date.date()})\")\n",
    "print(f\"   Test:  {len(X_test):,} (from {split_date.date()})\")\n",
    "print(f\"   Train Attack Rate: {(y_train > 0.5).mean()*100:.2f}%\")\n",
    "print(f\"   Test Attack Rate:  {(y_test > 0.5).mean()*100:.2f}%\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1051006",
   "metadata": {},
   "source": [
    "---\n",
    "## ü§ñ Step 7: Adaptive XGBoost Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b2897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 11: MODEL TRAINING\n",
    "# ============================================================\n",
    "print(\"ü§ñ TRAINING ADAPTIVE XGBOOST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n‚öôÔ∏è Hyperparameters:\")\n",
    "for k, v in CONFIG['XGB_PARAMS'].items():\n",
    "    print(f\"   {k}: {v}\")\n",
    "\n",
    "model = XGBRegressor(**CONFIG['XGB_PARAMS'])\n",
    "\n",
    "print(\"\\nüèãÔ∏è Training...\")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b555c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 12: FEATURE IMPORTANCE\n",
    "# ============================================================\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': FINAL_FEATURES,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, max(6, len(importance_df)*0.35)))\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(importance_df)))\n",
    "plt.barh(importance_df['feature'], importance_df['importance'], color=colors)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('üî¨ Feature Importance (XGBoost)', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/feature_importance_adaptive.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüèÜ TOP 5 FEATURES:\")\n",
    "for _, row in importance_df.tail(5).iloc[::-1].iterrows():\n",
    "    print(f\"   {row['feature']:30s} {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84150fa",
   "metadata": {},
   "source": [
    "---\n",
    "## üìà Step 8: Multi-Dimensional Validation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01118692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 13: PREDICTIONS\n",
    "# ============================================================\n",
    "print(\"üîÆ GENERATING PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "y_true_binary = (y_test > 0.5).astype(int)\n",
    "\n",
    "print(f\"   Predictions generated for {len(y_pred):,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7685112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 14: MULTI-DIMENSIONAL METRICS\n",
    "# ============================================================\n",
    "print(\"\\nüìà MULTI-DIMENSIONAL VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Overall regression metrics\n",
    "mae_total = mean_absolute_error(y_test, y_pred)\n",
    "rmse_total = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"\\nüéØ OVERALL REGRESSION:\")\n",
    "print(f\"   MAE:  {mae_total:.4f}\")\n",
    "print(f\"   RMSE: {rmse_total:.4f}\")\n",
    "\n",
    "# Dimensional MAE\n",
    "print(f\"\\nüìê DIMENSIONAL MAE:\")\n",
    "mae_1d = mean_absolute_error(test_df['score_1d'], y_pred)\n",
    "mae_2d = mean_absolute_error(test_df['score_2d'], y_pred)\n",
    "mae_3d = mean_absolute_error(test_df['score_3d'], y_pred)\n",
    "\n",
    "print(f\"   Metric 1D (Altitude/vAcc):   MAE = {mae_1d:.4f}\")\n",
    "print(f\"   Metric 2D (Horizontal/hAcc): MAE = {mae_2d:.4f}\")\n",
    "print(f\"   Metric 3D (Spatial):         MAE = {mae_3d:.4f}\")\n",
    "\n",
    "# Classification metrics\n",
    "print(f\"\\nüéØ CLASSIFICATION (Threshold 0.5):\")\n",
    "recall = recall_score(y_true_binary, y_pred_binary)\n",
    "precision = precision_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "f1 = f1_score(y_true_binary, y_pred_binary)\n",
    "\n",
    "print(f\"   Precision: {precision:.4f}\")\n",
    "print(f\"   Recall:    {recall:.4f}\")\n",
    "print(f\"   F1 Score:  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 15: CLASSIFICATION REPORT\n",
    "# ============================================================\n",
    "print(\"\\nüìä DETAILED CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_true_binary, y_pred_binary, \n",
    "                           target_names=['Safe', 'Attack']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab5154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 16: PREDICTION VS REALITY PLOT\n",
    "# ============================================================\n",
    "print(\"üìä VISUALIZATION: Prediction vs Reality\")\n",
    "\n",
    "# Find hardest case (attack period)\n",
    "attack_indices = test_df[test_df['degradation_score'] > 0.5].index\n",
    "if len(attack_indices) > 100:\n",
    "    center_idx = attack_indices[len(attack_indices)//2]\n",
    "    plot_start = max(test_df.index[0], center_idx - 300)\n",
    "    plot_end = min(test_df.index[-1], center_idx + 300)\n",
    "    \n",
    "    plot_df = test_df.loc[plot_start:plot_end].copy()\n",
    "    plot_pred = y_pred[plot_df.index - test_df.index[0]]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "    \n",
    "    # Top: Scores\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(plot_df['timestamp'], plot_df['degradation_score'], \n",
    "             color='blue', alpha=0.6, label='Actual Score (Max 1D/2D/3D)')\n",
    "    ax1.plot(plot_df['timestamp'], plot_pred, \n",
    "             color='red', linewidth=2, label='Predicted Score')\n",
    "    ax1.axhline(0.5, color='gray', linestyle=':', label='Threshold')\n",
    "    ax1.fill_between(plot_df['timestamp'], 0, plot_df['degradation_score'], \n",
    "                     where=plot_df['degradation_score'] > 0.5, \n",
    "                     color='red', alpha=0.2, label='Attack Zone')\n",
    "    ax1.set_ylabel('Score')\n",
    "    ax1.set_title('üéØ Prediction vs Reality (Hardest Case)', fontweight='bold')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 1.05)\n",
    "    \n",
    "    # Bottom: Individual dimensions\n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(plot_df['timestamp'], plot_df['score_1d'], \n",
    "             color='green', alpha=0.7, label='1D (Altitude)')\n",
    "    ax2.plot(plot_df['timestamp'], plot_df['score_2d'], \n",
    "             color='orange', alpha=0.7, label='2D (Horizontal)')\n",
    "    ax2.plot(plot_df['timestamp'], plot_df['score_3d'], \n",
    "             color='purple', alpha=0.7, label='3D (Spatial)')\n",
    "    ax2.axhline(0.5, color='gray', linestyle=':')\n",
    "    ax2.set_ylabel('Score')\n",
    "    ax2.set_xlabel('Time')\n",
    "    ax2.set_title('üìê Individual Dimension Scores', fontweight='bold')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0, 1.05)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../figures/prediction_vs_reality_adaptive.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Not enough attack samples for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c2595",
   "metadata": {},
   "source": [
    "---\n",
    "## üíæ Step 9: Save Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 17: SAVE MODEL & CONFIG\n",
    "# ============================================================\n",
    "print(\"üíæ SAVING MODEL & CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create directory\n",
    "os.makedirs(os.path.dirname(CONFIG['MODEL_OUTPUT_PATH']), exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model.save_model(CONFIG['MODEL_OUTPUT_PATH'])\n",
    "print(f\"   ‚úÖ Model: {CONFIG['MODEL_OUTPUT_PATH']}\")\n",
    "\n",
    "# Save config\n",
    "model_config = {\n",
    "    'model_name': 'gnss_adaptive_3d',\n",
    "    'version': '2.1.0',\n",
    "    'author': 'Sofia Buriak',\n",
    "    'description': 'Adaptive 3D GNSS Degradation Model with Auto-Feature Selection',\n",
    "    'input_features': FINAL_FEATURES,\n",
    "    'hyperparameters': CONFIG['XGB_PARAMS'],\n",
    "    'target_engineering': {\n",
    "        'safe_limit_mm': CONFIG['SAFE_LIMIT_MM'],\n",
    "        'fail_limit_mm': CONFIG['FAIL_LIMIT_MM'],\n",
    "        'method': 'max(1D, 2D, 3D)'\n",
    "    },\n",
    "    'metrics': {\n",
    "        'mae': float(mae_total),\n",
    "        'rmse': float(rmse_total),\n",
    "        'mae_1d': float(mae_1d),\n",
    "        'mae_2d': float(mae_2d),\n",
    "        'mae_3d': float(mae_3d),\n",
    "        'recall': float(recall),\n",
    "        'precision': float(precision),\n",
    "        'f1': float(f1)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(CONFIG['CONFIG_OUTPUT_PATH'], 'w') as f:\n",
    "    json.dump(model_config, f, indent=4)\n",
    "print(f\"   ‚úÖ Config: {CONFIG['CONFIG_OUTPUT_PATH']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10609fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 18: FINAL SUMMARY\n",
    "# ============================================================\n",
    "print(\"\\n\")\n",
    "print(\"=\"*70)\n",
    "print(\"üèÜ FINAL SUMMARY: Adaptive 3D GNSS Model\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä MODEL ARCHITECTURE:\n",
    "   ‚Ä¢ Algorithm:      XGBoost Regressor (reg:logistic)\n",
    "   ‚Ä¢ Features:       {len(FINAL_FEATURES)} auto-selected features\n",
    "   ‚Ä¢ Target:         Max(1D, 2D, 3D) Degradation Score\n",
    "   ‚Ä¢ Estimators:     {CONFIG['XGB_PARAMS']['n_estimators']}\n",
    "\n",
    "üìà MULTI-DIMENSIONAL METRICS:\n",
    "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "   ‚îÇ Dimension          ‚îÇ MAE      ‚îÇ\n",
    "   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "   ‚îÇ 1D (Altitude)      ‚îÇ {mae_1d:.4f}   ‚îÇ\n",
    "   ‚îÇ 2D (Horizontal)    ‚îÇ {mae_2d:.4f}   ‚îÇ\n",
    "   ‚îÇ 3D (Spatial)       ‚îÇ {mae_3d:.4f}   ‚îÇ\n",
    "   ‚îÇ Overall            ‚îÇ {mae_total:.4f}   ‚îÇ\n",
    "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "üéØ CLASSIFICATION (Attack Detection):\n",
    "   ‚Ä¢ Precision: {precision:.4f}\n",
    "   ‚Ä¢ Recall:    {recall:.4f}\n",
    "   ‚Ä¢ F1 Score:  {f1:.4f}\n",
    "\n",
    "üíæ SAVED TO:\n",
    "   ‚Ä¢ Model:  {CONFIG['MODEL_OUTPUT_PATH']}\n",
    "   ‚Ä¢ Config: {CONFIG['CONFIG_OUTPUT_PATH']}\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ MODEL READY FOR DEPLOYMENT!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
