import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb
from sklearn.metrics import mean_absolute_error, mean_squared_error
import gc

# ==========================================
# 1. –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –î–ê–ù–ò–•
# ==========================================
DATA_PATH = 'data/processed/all_data_compressed.parquet'
print("üìÇ Loading full dataset...")
df = pd.read_parquet(DATA_PATH)
df = df.sort_values('timestamp').reset_index(drop=True)

if not np.issubdtype(df['timestamp'].dtype, np.datetime64):
    df['timestamp'] = pd.to_datetime(df['timestamp'])

# –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º—ñ—Å—è—Ü—å, –±–æ timestamp –º–∏ —Å–∫–æ—Ä–æ –≤–∏–¥–∞–ª–∏–º–æ –¥–ª—è –µ–∫–æ–Ω–æ–º—ñ—ó
df['month'] = df['timestamp'].dt.month.astype(np.int8) # int8 –µ–∫–æ–Ω–æ–º–∏—Ç—å –ø–∞–º'—è—Ç—å

print(f"   Months available: {df['month'].unique()}")

# ==========================================
# 2. FEATURE ENGINEERING
# ==========================================
print("üõ†Ô∏è Engineering features...")

# Target
SAFE_LIMIT, FAIL_LIMIT = 5000, 50000
df['degradation_score'] = ((df['hAcc'] - SAFE_LIMIT) / (FAIL_LIMIT - SAFE_LIMIT)).clip(0.0, 1.0).astype(np.float32)

# Physics
if 'numSV' in df.columns:
    df['sat_efficiency'] = (df['numSV'] / df['numSatsTracked'].replace(0, 1)).clip(0, 5).astype(np.float32)
else:
    df['sat_efficiency'] = 0.0

# Rolling Features (–û–¥—Ä–∞–∑—É —É float32)
df = df.set_index('timestamp')
cols_to_roll = ['cnoMean', 'sat_efficiency']

for col in cols_to_roll:
    if col in df.columns:
        for w in ['5s', '10s']:
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ .values, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –∑–∞–π–≤–∏—Ö —ñ–Ω–¥–µ–∫—Å—ñ–≤
            roll = df[col].rolling(w)
            df[f'{col}_rolling_mean_{w}'] = roll.mean().astype(np.float32)
            df[f'{col}_rolling_std_{w}'] = roll.std().fillna(0).astype(np.float32)

df = df.reset_index()

# Lags
for col in ['cnoMean', 'sat_efficiency']:
    if col in df.columns:
        df[f'{col}_lag1'] = df[col].shift(1).bfill().astype(np.float32)

features = ['cnoMean', 'cnoStd', 'numSV', 'numSatsTracked', 'sat_efficiency'] + \
           [c for c in df.columns if 'rolling' in c] + \
           [c for c in df.columns if 'lag' in c]
features = [f for f in features if f in df.columns]

# ==========================================
# 3. MEMORY OPTIMIZATION (–ö—Ä–∏—Ç–∏—á–Ω–∏–π –µ—Ç–∞–ø!)
# ==========================================
print("üßπ Aggressive Memory Cleanup...")

# 1. –ó–∞–ª–∏—à–∞—î–º–æ –¢–Ü–õ–¨–ö–ò —Ç–µ, —â–æ —Ç—Ä–µ–±–∞ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è. 
# –í–∏–¥–∞–ª—è—î–º–æ 'timestamp', 'hAcc', 'vAcc' —Ç–∞ –≤—Å—ñ —Å–∏—Ä—ñ —Ä—è–¥–∫–∏
cols_to_keep = features + ['degradation_score', 'month']
df = df[cols_to_keep]

# 2. –ü—Ä–∏–º—É—Å–æ–≤–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –≤ float32 (–∑–º–µ–Ω—à—É—î —Ä–æ–∑–º—ñ—Ä —É 2 —Ä–∞–∑–∏ –ø–æ—Ä—ñ–≤–Ω—è–Ω–æ –∑ float64)
float_cols = df.select_dtypes(include=['float64']).columns
if len(float_cols) > 0:
    df[float_cols] = df[float_cols].astype(np.float32)

# 3. –í–∏–∫–ª–∏–∫–∞—î–º–æ –∑–±–∏—Ä–∞—á —Å–º—ñ—Ç—Ç—è
gc.collect()

print(f"   Dataset shape after cleanup: {df.shape}")

# ==========================================
# 4. STRICT TIME SPLIT
# ==========================================
print("\n‚úÇÔ∏è Splitting Data by Time:")

# –°–ø–æ—á–∞—Ç–∫—É —Ä–æ–±–∏–º–æ –º–∞—Å–∫—É
mask_december = df['month'] == 12

# 1. –í–∏–¥—ñ–ª—è—î–º–æ TEST (–ì—Ä—É–¥–µ–Ω—å)
X_test = df.loc[mask_december, features]
y_test = df.loc[mask_december, 'degradation_score']
print(f"   Test samples (Dec):  {len(X_test)}")

# 2. –í–∏–¥—ñ–ª—è—î–º–æ TRAIN (–°—ñ—á–µ–Ω—å-–õ–∏—Å—Ç–æ–ø–∞–¥)
# –û–¥—Ä–∞–∑—É —Ñ—ñ–ª—å—Ç—Ä—É—î–º–æ! –ù–µ —Å—Ç–≤–æ—Ä—é—î–º–æ train_full
train_subset = df[~mask_december]

# –í–∏–¥–∞–ª—è—î–º–æ df, —â–æ–± –∑–≤—ñ–ª—å–Ω–∏—Ç–∏ –ø–∞–º'—è—Ç—å –ø—ñ–¥ —á–∞—Å downsampling
del df, mask_december
gc.collect()

# --- Smart Downsampling –¥–ª—è Train ---
print("   Downsampling Train Data...")
mask_attack = train_subset['degradation_score'] > 0.05
mask_safe = train_subset['degradation_score'] <= 0.05

# –ë–µ—Ä–µ–º–æ 100% –∞—Ç–∞–∫ —ñ 25% —Ç–∏—à—ñ
train_attack = train_subset[mask_attack]
train_safe = train_subset[mask_safe].sample(frac=0.25, random_state=42)

# –û–±'—î–¥–Ω—É—î–º–æ
X_train = pd.concat([train_attack[features], train_safe[features]])
y_train = pd.concat([train_attack['degradation_score'], train_safe['degradation_score']])

# –ü–µ—Ä–µ–º—ñ—à—É—î–º–æ
perm = np.random.permutation(len(X_train))
X_train = X_train.iloc[perm]
y_train = y_train.iloc[perm]

print(f"   Train samples (Opt): {len(X_train)}")

# –ß–∏—Å—Ç–∏–º–æ —Ö–≤–æ—Å—Ç–∏
del train_subset, train_attack, train_safe
gc.collect()

# ==========================================
# 5. –ù–ê–í–ß–ê–ù–ù–Ø
# ==========================================
print("\nü§ñ Training XGBoost on Past Data...")
model = xgb.XGBRegressor(
    objective='reg:logistic',
    n_estimators=100,
    max_depth=6,
    learning_rate=0.05,
    tree_method='hist',
    n_jobs=-1
)

model.fit(X_train, y_train)
print("‚úÖ Model Trained!")

# ==========================================
# 6. –ü–†–û–ì–ù–û–ó –ù–ê –ú–ê–ô–ë–£–¢–ù–Ñ
# ==========================================
print("üîÆ Predicting December...")
y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"\nüìä RESULTS ON UNSEEN DATA (DECEMBER):")
print(f"   MAE:  {mae:.4f}")
print(f"   RMSE: {rmse:.4f}")

# ==========================================
# 7. –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø
# ==========================================
# –®—É–∫–∞—î–º–æ –∞—Ç–∞–∫—É –≤ –≥—Ä—É–¥–Ω—ñ –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≥—Ä–∞—Ñ—ñ–∫—É
y_test_np = y_test.values
subset_mask = (y_test_np > 0.1) 

if subset_mask.sum() > 0:
    idx_start = np.where(subset_mask)[0][0]
    # –ë–µ—Ä–µ–º–æ —Ç—Ä–æ—Ö–∏ –¥–æ —ñ —Ç—Ä–æ—Ö–∏ –ø—ñ—Å–ª—è –∞—Ç–∞–∫–∏
    plot_slice = slice(max(0, idx_start - 200), min(len(y_test), idx_start + 800))
    print(f"\nüìà Plotting specific attack in December...")
else:
    plot_slice = slice(0, 1000)

plt.figure(figsize=(12, 6))
plt.plot(np.arange(len(y_test))[plot_slice], y_test_np[plot_slice], label='REALITY (GPS)', color='black', alpha=0.5)
plt.plot(np.arange(len(y_test))[plot_slice], y_pred[plot_slice], label='FORECAST (Model)', color='red', linewidth=2, alpha=0.8)

# –ó–≥–ª–∞–¥–∂—É–≤–∞–Ω–Ω—è –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
smooth_pred = pd.Series(y_pred[plot_slice]).rolling(10, min_periods=1).mean()
plt.plot(np.arange(len(y_test))[plot_slice], smooth_pred, label='Smoothed Output', color='blue', linewidth=2)

plt.title('Validation on Future Data (December)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()