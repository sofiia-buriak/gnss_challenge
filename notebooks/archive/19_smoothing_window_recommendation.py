import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from xgboost import XGBRegressor

# ==========================================
# 1. –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –¢–ê –ü–Ü–î–ì–û–¢–û–í–ö–ê (–ê–í–¢–û–ù–û–ú–ù–û)
# ==========================================
DATA_PATH = 'data/processed/all_data_compressed.parquet'
print("üìÇ Loading data...")
df = pd.read_parquet(DATA_PATH)
df = df.sort_values('timestamp').reset_index(drop=True)
if not np.issubdtype(df['timestamp'].dtype, np.datetime64):
    df['timestamp'] = pd.to_datetime(df['timestamp'])

# Target
SAFE_LIMIT, FAIL_LIMIT = 5000, 50000
df['degradation_score'] = ((df['hAcc'] - SAFE_LIMIT) / (FAIL_LIMIT - SAFE_LIMIT)).clip(0.0, 1.0)

# Features
if 'numSV' in df.columns:
    df['sat_efficiency'] = (df['numSV'] / df['numSatsTracked'].replace(0, 1)).clip(0, 5)
else:
    df['sat_efficiency'] = 0.0

df = df.set_index('timestamp')
for col in ['cnoMean', 'sat_efficiency']:
    if col in df.columns:
        for w in ['5s', '10s']:
            df[f'{col}_rolling_mean_{w}'] = df[col].rolling(w).mean().astype(np.float32)
            df[f'{col}_rolling_std_{w}'] = df[col].rolling(w).std().fillna(0).astype(np.float32)
df = df.reset_index()

for col in ['cnoMean', 'sat_efficiency']:
    if col in df.columns:
        df[f'{col}_lag1'] = df[col].shift(1).bfill().astype(np.float32)

features = ['cnoMean', 'cnoStd', 'numSV', 'numSatsTracked', 'sat_efficiency'] + \
           [c for c in df.columns if 'rolling' in c] + \
           [c for c in df.columns if 'lag' in c]
features = [f for f in features if f in df.columns]

# ==========================================
# 2. –®–í–ò–î–ö–ò–ô –ü–ï–†–ï–†–ê–•–£–ù–û–ö –ú–û–î–ï–õ–Ü
# ==========================================
print("ü§ñ Quick Model Retrain (to get raw predictions)...")
split_date = pd.Timestamp('2025-12-01')
# –ë–µ—Ä–µ–º–æ –º–∞–ª–µ–Ω—å–∫—É –≤–∏–±—ñ—Ä–∫—É –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ (–Ω–∞–º —Ç—Ä–µ–±–∞ –ª–∏—à–µ —Ç—Ä–µ–Ω–¥)
train = df[df['timestamp'] < split_date].sample(frac=0.2, random_state=42)
test = df[df['timestamp'] >= split_date].copy()

model = XGBRegressor(
    objective='reg:logistic', 
    n_jobs=-1, 
    tree_method='hist',
    n_estimators=100, 
    max_depth=6
)
model.fit(train[features], train['degradation_score'])

print("üîÆ Predicting...")
test['pred_raw'] = model.predict(test[features])

# ==========================================
# 3. –ü–û–®–£–ö –ó–û–ù–ò –•–ê–û–°–£ (Re-Find Chaos Zone)
# ==========================================
print("üîç Re-locating the chaos zone...")
# –®—É–∫–∞—î–º–æ –¥–µ —Å–∏–≥–Ω–∞–ª —Å—Ç—Ä–∏–±–∞–≤ –Ω–∞–π—Å–∏–ª—å–Ω—ñ—à–µ
test['volatility'] = test['pred_raw'].diff().abs().rolling(60).sum()
chaos_idx = test['volatility'].idxmax()
chaos_time = test.loc[chaos_idx, 'timestamp']

print(f"üìç Chaos found at: {chaos_time}")

# –í–∏—Ä—ñ–∑–∞—î–º–æ –≤—ñ–∫–Ω–æ 4 —Ö–≤–∏–ª–∏–Ω–∏
start_t = chaos_time - pd.Timedelta(seconds=120)
end_t = chaos_time + pd.Timedelta(seconds=120)
subset = test[(test['timestamp'] >= start_t) & (test['timestamp'] <= end_t)].copy()

# ==========================================
# 4. –ü–Ü–î–ë–Ü–† –í–Ü–ö–ù–ê (GRID SEARCH)
# ==========================================
print("\nüß™ TESTING WINDOW SIZES:")
windows = [10, 30, 60, 90, 120]
results = []
colors = ['red', 'orange', 'gold', 'green', 'blue']

plt.figure(figsize=(14, 8))
plt.plot(subset['timestamp'], subset['pred_raw'], color='lightgray', label='Raw Model Output', alpha=0.6)

for i, w in enumerate(windows):
    col_name = f'smooth_{w}s'
    # –†–∞—Ö—É—î–º–æ —Å–µ—Ä–µ–¥–Ω—î
    subset[col_name] = subset['pred_raw'].rolling(window=w, min_periods=1).mean()
    # –†–∞—Ö—É—î–º–æ —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å (—á–∏–º –º–µ–Ω—à–µ std, —Ç–∏–º –∫—Ä–∞—â–µ)
    stability = subset[col_name].std()
    
    status = "‚úÖ ACCEPTABLE" if stability < 0.1 else "‚ùå TOO NOISY"
    print(f"   Window {w}s -> Std Dev: {stability:.4f} | {status}")
    
    results.append({'window': w, 'stability': stability})
    
    plt.plot(subset['timestamp'], subset[col_name], 
             label=f'Window {w}s ($\sigma$={stability:.2f})', 
             linewidth=2, color=colors[i])

plt.title(f'Smoothing Window Optimization\nChaos Event at {chaos_time}')
plt.ylabel('Score Stability')
plt.xlabel('Time')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è
best_win = None
for res in results:
    if res['stability'] < 0.1:
        best_win = res['window']
        break

print("-" * 40)
if best_win:
    print(f"üèÜ FINAL RECOMMENDATION: Use a **{best_win}-second** Moving Average.")
    print(f"   Reason: It's the smallest window that keeps noise below 0.1.")
else:
    print(f"‚ö†Ô∏è RECOMMENDATION: Use **120+ seconds** or a Hysteresis Filter.")